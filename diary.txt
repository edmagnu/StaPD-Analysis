Looking for interesting data files.
In 'Documents\Data\Static Bulk Analysis' there is a 'Results.ipynb'.
In this notebook it loads data from '2016-09-22', '2016-09-23to27', '2016-09-27', '2016-09-28', '2016-10-01', 2016-10-04'
These are likely the data folders I'm looking for.
The notebook references each folder having an 'out.txt'. What's this?

In 'Documents\Data\2016-09-22'
'out.txt' is 19 lines of 4 floats each. The context is unclear.
'Results.ipynb' writes 'out.txt'.
It's a numpy array of 'fpulses', 'means', 'amps' and 'phases'.
How are these produced?

'fpulses' is read straight from a datafile, 'dscanmap.txt'
'dscanmap.txt' is a manually typed list of data files and the conditions of the data run.
It has the info [fnum (file number), DL-Pro (absolute DL-Pro frequency in GHz), DL-100 (same for DL-100), MW f (same for microwave frequency), attn (MW attenuation of variable attenuator, dB), fpulse (voltage pulse applied to vertical plate in mV)].
All delay scan files are listed.
So 'fpulses' is the static voltage pulse in mV applied to the top (or bottom) plate.

'means', 'phases' and 'amps' are produced by 'Results.ipynb'.
They are all set by 'delay_scan()', after which amp and phase are changed together so amp > 0 and phase is mod 1.
'delay_scan()' reads a delay data run.
First it zero corrects and averages.
Then it fits with 'fit_cos_3()'. A basic y = amp * cos(2*pi*(x-x0)) + y0
'amps' -> amp, 'phases' -> x0 and 'means' -> y0.
Note that the delay steps from the stage are translated to distance, and then divided by the MW wavelenght before being passed to the fit. So x0 is the phase in terms of wavelength offsets.

So we know that 'fpulses' describes the varied experimental condition, and 'amps', 'means' and 'phases' are the fit values.
This is all the information from inside a data set that we need for each data run.
'out.txt' should give all of the meaningful information from a data run.

Lets start on Git so I'm not tied to this computer.
Made a git repo StaPD-Analysis 'git init' and 'git add'
Used .gitignore to exclude '*.pdf'
Pushed to GitHub and cloned on laptop 'git push origin master'
'https://github.com/edmagnu/StaPD-Analysis.git'
Branching? I'll see when I get there.

Now that I have the data, I should look at metadata cleaning.
Focus on '#_delay.txt' files for now.
Necessary metadata:
	'date', 'dlpro', 'dl100', 'static', 'mwon', 'mwf', 'attn'
	Use 'other' to store the rest of the info in a long string.
Use '# key: metadata' format.

'Original Data' folders marked 'Read Only'
Will test metadata format on '2016-09-22\6_delay.txt'
'6_delay.txt' is reformatted. All comments are metadata, I can pick which ones to use.
'Analysis.py' is created. Imports metadata and data from '6_delay.txt' into DataFrame
For now I'll just try and read all files in the folder meeting the '#_delay.txt' format.
That means I have to reformat all the metadata

Metadata by hand would take 3min/file, 1 hour per folder.
I'll try to write something to do the heavy lifting.
'metadata_cleaner.py' does this.
I've been successful. All the metadata from "8_delay.txt" has been handled, and any extra gets stored in "Other".
"Filename", "Date", "Title", "DLPro", "DL100", "Static", "MWOn", "MWf", "Attn" are all essential, others are optional.

"metadata_cleaner()" did it's job. I ran it on these folders.
"2016-09-22", "2016-09-23", "2016-09-24", "2016-09-26", "2016-09-27", "2016-09-28", "2016-10-01", "2016-10-04"
I gave a quick quality control check, they look good.

Files all have trailing tabs, modifying 'metadata_cleaner()" to "line.strip()"
"flist_clean()" reads folders from "data_folders.txt" and cleans them.
Column labels fixed to be tab separated.
Tested with "read_tidy()", data loaded succesfully.

Now I need to read all data files into one big DataFrame.
First I aught to get a proper list of files.
Reads "data_folders.txt" to get the list of data folders.

All files in each folder gets read in.
This naturally produces errors when there are big typos.
I will add an editing step to "metadata_cleaner()" to fix typos.
I need to go error by error, and track down the right "fix."

"2016-09-27\20_delay.txt":
	Static is '15-00 mV Pulsed"
	This could be +/- 1500 mV
	According to "dscanmap.txt", it is +1500 mV
	"21_delay.txt" is -1500 mV
It looks like that's the only typo. For now.

I sould check that all of the important metadata is correct.
	Laser Frequency: Double check each day vs record
		Also check DL-Pro vs DL-100
	MW Frequency: Aught to be ~15930 MHz
	Static: Between -3000 and 3000 mV, good +/- coverage
	Attn: 53 - 10 dB
	MWOn: Should always be on for these data.

Looking at laser frequencies, "2016-10-01" has DL-Pro < 300 THz.
Specifically, 36588.5 GHz, nonsense
Must be a typo, forgot the last digit.
Knowing DL-100 and MWf might help.
Problem in Original and Modified data.
DL-100 is always 36587.6 GHz, MWf is always 15932.0 MHz
So DL-Pro must be either 365856.7 or 365888.5 GHz
365888.5 GHz is a sensible typo, and puts DL-Pro above Dl-100.
Check that it's in the folder AND DL-Pro = 36588.5
All other DL-Pro metadata are reasonable, but still should check.

Check commit history with "git log"

I want a list of just files and metadata from "data".
Get rid of all of the experimental data (i, signal, ...)
"DataFrame.drop_duplicates()" removes the many copies, cuts down to the 189 unique data files and their metadata.

Metadata checks:
	DL-Pro is only 5 values
		365872.6, 365856.7, 365840.7, 365824.8, 365888.5
	DL-100 is only 5 values
		365856.7, 365840.7, 365824.8, 365808.9, 365872.6
	MWf is always between 15931.0 and 15933.0 MHz
	DL-Pro - DL-100 is always 15.9 or 16 GHz
		Also says DL-Pro > DL-100, as intended.
	MWOn is always 1.0, always "On"
	Static is always mod 10 between +/- 8000 mV
	Attn always 5 values
		38, 44, 50, 32, 26 dB

Now I need to look at the metadata file by file.
	2016-09-22:
		Attn is 38 in Original record, 44 on dscanmap
		This could be very bad?
		I'm leaving it at 44 for now, I can look at lab notes later.
	2016-09-23:
		"16_delay.txt" & "17_delay.txt" are commented out of "dscanmap.txt". At the time, determined by experimental condition check (exp. cond. check) to be bad.
		3, 4 are left off "dscanmap.txt"
			They were reference scans for relative phase.
		Ignoring MWf rounding errors <100 kHz
		11 & 12 left off "dscanmap.txt"
			Bad data by exp. cond. check.
	2016-09-24:
		All DL-Pro and DL-100 values don't match "dscanmap.txt"
		365856.7 & 365840.7 in "dscanmap.txt"
		365872.6 & 365856.7 in data files.
		Will have to look at notes to resolve.
	2016-09-26:
		8 & 9 excluded by exp. cond. check.
	2016-09-27:
		7 ignored by exp. cond. check.
		15 Ignored, repeat data point
	2016-09-28:
		DL-Pro has small error
			365824.8 in data listed as 365828.8 in dscanmap.txt"
			MWf and DL-100 shows it must be 24.8.
			Not marked, not very significant
		2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 ignored by exp. cond. check.
		9 & 10 static fields sign flip.
		27 ignored by exp. cond. check.
	2016-10-01:
		MWf 15932.0 in files, 15931.9 in dscanmap
			Ignoring 100 kHz error
		3 & 4 & 9 & 22 ignored by exp. cond. check.
		2 ignored, reference phsae delay? At different dl freq.
	2016-10-04:
		Laser frequencies don't match
			Data says 365824.8 & 365808.9
			dscanmap says 365888.5 & 365872.6
			I need to look at records to resolve.
Aside from listed (very serious) discrepencies, the metadata is good.
I can look at "out.txt", "Analysis.ipnb" and "Results.ipnb" for each to get more information.
"out.txt" is just static field and fit results, not helpful.

Lets get a better idea of what the big results I have are.
The "Static Bulk Analysis" has "Results.ipynb", "Analysis.ipynb" and "Pictures.ipynb".
"Analysis.ipynb" is to look individually at each delay scan, see if the fit and data are decent.
"Results.ipynb" groups data sets as follows:
	data856 from "2016-09-22"
	data840 from "2016-09-23to27"
	data824 from "2016-09-27"
	data808 from "2016-09-28"
	data872w from "2016-10-01"
	data872s from "2016-10-04"
These arrays pull form "out.txt" in each folder.
The primary result plot uses
	data872w, data856, data840, data824, data808
	Claims they are all at 44 dB.
	I should look at what files are actually in "out.txt"
	Except "out.txt" is taken from "dscanmap.txt"
	I should look at "2016-09-23to27\dscanmap.txt"

"Pictures.ipynb" produces the plot I've been showing Gallagher
	Also groups the data into data808, data824, data840, data856, data872w
	Also claims all of these are at 44 dB

If I just look at the metadata, what groups of conditions do I have?
Do they contradict what I have record of?
	"2016-09-22":
		365872.6 & 365856.7 & 38 dB & ZFIL - 05 GHz & DIL + 02 GHz
	"2016-09-23":
		365856.7 & 365840.7 & 44 dB & ZFIL - 21 GHz & DIL - 14 GHz
	"2016-09-24":
		365872.6 & 365856.7 & 44 dB & ZFIL - 05 GHz & DIL + 02 GHz
	"2016-09-26":
		365856.7 & 365840.7 & 44 dB & ZFIL - 21 GHz & DIL - 14 GHz
	"2016-09-27":
		365840.7 & 365824.8 & 44 dB & ZFIL - 37 GHz & DIL - 30 GHz
	"2016-09-28":
		365824.8 & 365808.9 & 44 dB & ZFIL - 53 GHz & DIL - 46 GHz
	"2016-10-01":
		365888.5 & 365872.6 & 44 dB & ZFIL + 11 GHz & DIL + 18 GHz
	"2016-10-04":
		365824.8 & 365808.9 & 32 dB & ZFIL - 53 GHz & DIL - 46 GHz
Naively, I'd like to look at 44 dB
	+18, "2016-10-01"
	+2, "2016-09-24"
	-14, "2016-09-23" & "2016-09-26"
	-30, "2016-09-27"
	-46, "2016-09-28"
Two ways to go:
	Look at the picture sources and see what they're doing.
	Start building data analysis so I can look.

Lets ask what I need to do for analysis.
Each file needs to be looked at independently.
From it, fit parameters have to be extracted.
I should hold a DataFrame separate from the measurements, but with the same metadata.
First, lets write the master dataframe to a file so I don't reload it every time. "rawdata.txt"

I need to transform the data, as r4ds says.
Steps must be converted to wavelength using MWf & translation stage calibration.
signal, sbackground, norm, nbackground need to build nsignal
This should be done before writing "rawdata.txt"

Start with wavelength.
Delay stage calibration from "Analysis.ipynb", "wavelength()"
m = 0.0002539 mm/step = 2.539e-4 mm/step
c = 299792458 m/s, n_air = 1.0003